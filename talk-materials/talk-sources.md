# Sources for talk: Can you trust your (large language) model?

Below is a list of all the sources and media I used for this talk.

## Papers, articles and examples
* Dominus (2017). [When the revolution came for Amy Cuddy](https://www.nytimes.com/2017/10/18/magazine/when-the-revolution-came-for-amy-cuddy.html).
* Simmons & Simonsohn (2015). [Power posing: Reassessing the evidence behind the most popular TED talk](https://datacolada.org/37).
* Carney et al. (2010). [Power posing: brief nonverbal displays affect neuroendocrine levels and risk tolerance](https://faculty.haas.berkeley.edu/dana_carney/power.poses.PS.2010.pdf).
* Kapoor & Narayanan (2023). [Leakage and the reproducibility crisis in machine learning-based science](https://www.cell.com/patterns/pdfExtended/S2666-3899(23)00159-9).
* Rosenblatt et al. (2024). [Data leakage inflates prediction performance in connectome-based machine learning models](https://www.nature.com/articles/s41467-024-46150-w.pdf).
* Burchell (2015). [Interpreting linear regression coefficients](https://t-redactyl.io/blog/2015/10/interpreting-linear-regression-coefficients.html).
* Chollet (2021). [Deep Learning with Python](https://www.manning.com/books/deep-learning-with-python). 
* Vig (2019). [A Multiscale Visualization of Attention in the Transformer Model](https://aclanthology.org/P19-3007/).
* Lahiri (2024). [The benchmark trap: Why LLM metrics mislead and evals enlighten](https://ribhulahiri.com/posts/llm-benchmarks/).
* Hugging Face (2024). [Open LLM Leaderboard (now archived)](https://huggingface.co/spaces/open-llm-leaderboard-old/open_llm_leaderboard).
* Abbas et al. (2024). [Comparing the Performance of Popular Large Language Models on the National Board of Medical Examiners Sample Questions](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11007479/).
* Wu et al. (2022). [Medical school grades may predict future clinical competence](https://journals.lww.com/jcma/fulltext/2022/09000/medical_school_grades_may_predict_future_clinical.6.aspx). 
* Ellis et al. (2021). [Does performance at medical school predict success at the (MRCS) examination?](https://bmjopen.bmj.com/content/11/8/e046615)
* Chollet (2019). [On the measure of intelligence](https://arxiv.org/pdf/1911.01547).
* Theory of mind [tweets](https://x.com/NLPurr/status/1645566865601855489).
* [Tweets](https://x.com/AIExplainedYT/status/1782716249639670000) about bizarre benchmark questions.
* Chen (2024). [HellaSwag or HellaBad?](https://www.surgehq.ai/blog/hellaswag-or-hellabad-36-of-this-popular-llm-benchmark-contains-errors)
* Li et al. (2024). [Can multiple-choice questions really be useful in detecting the abilities of LLMs?](https://arxiv.org/pdf/2403.17752v3)
* Nezhurina et al. (2024). [Alice in Wonderland: Simple tasks showing complete reasoning breakdown in state-of-the-art large language models](https://arxiv.org/pdf/2406.02061).
* Nest (2023). [LLM benchmarks: What do they all mean?](https://www.whytryai.com/p/llm-benchmarks)
* LMSYS & UC Berkeley SkyLab (2024). [Chatbot Arena](https://lmarena.ai/).
* [Andrej Karpathy](https://x.com/karpathy/status/1737544497016578453) on the Chatbot Arena.
* Horace He's [Codeforces example](https://x.com/cHHillee/status/1635790330854526981?t=bdVc5pxCn1P_GV3ZF91X6w&s=35).
* Sayash Kapoor's [Codeforces example](https://x.com/sayashk/status/1638159652562038787).
* Balloccu et al. (2024). [Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs](https://arxiv.org/pdf/2402.03927).
* Villalobos et al. (2024). [Will We Run Out of Data? Limits of LLM Scaling Based on Human-Generated Data](https://arxiv.org/pdf/2211.04325).
* Sclar et al. (2024). [Quantifying language modelsâ€™ sensitivity to spurious features in prompt design](https://openreview.net/pdf?id=RIu5lyNXjT).
* Cao et al. (2024). [On the worst prompt performance of large language models](https://arxiv.org/pdf/2406.10248).
* Husain (2024). [Your AI product needs evals](https://hamel.dev/blog/posts/evals/).

## Images credits
* [Pinocchio image](https://motionarray.com/stock-photos/pinocchio-782004/?q=pinocchio&search_header=1) purchased from MotionArray
* [Person with laptop icon](https://www.flaticon.com/free-icon/computer-worker_7870360?term=laptop&page=2&position=1&origin=search&related_id=7870360) from Flaticon
* [Neural net](https://www.flaticon.com/free-icon/deep-learning_10328741?term=neural+network&page=1&position=95&origin=style&related_id=10328741) icons from Flaticon